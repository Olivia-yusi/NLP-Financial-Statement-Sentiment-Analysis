{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing built-in libraries \n",
    "import re\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "from datetime import datetime, timedelta\n",
    "import unicodedata\n",
    "\n",
    "# Importing libraries you may need to install\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "import bs4 as bs\n",
    "from lxml import html\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wikipedia download current SP 500 list with symbol/ticker and CIK\n",
    "cwd=os.getcwd()\n",
    "res=requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "# if requests fail, show the failure\n",
    "if res.status_code != 200:\n",
    "    text='Request to list SP 500 companies fails with error code' + str(res.status_code)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sptable is the table with SP500 company list\n",
    "soup= bs.BeautifulSoup(res.text,'lxml')\n",
    "tables=soup.find_all('table')\n",
    "sptable = pd.read_html(str(tables[0]), header=0)[0]\n",
    "sptable.to_csv('sp500_companylist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIK data type: <class 'numpy.int64'>\n",
      "CIK data type after modification: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# CIK in sptable is an integer which does not have preceding zeros, need to convert to string with preceding zeros\n",
    "print('CIK data type:',type(sptable['CIK'][0]))\n",
    "sptable['CIK']=[str(cik).zfill(10) for cik in sptable['CIK']]\n",
    "print('CIK data type after modification:',type(sptable['CIK'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder that you want to save the 10k and 10q reports for SP500 companies (need to change to your own folder)\n",
    "pathname_10k = '/Users/oliviali/Downloads/10K'\n",
    "pathname_10q = '/Users/oliviali/Downloads/10Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteLogFile(log_file_name, text):\n",
    "    \n",
    "    '''\n",
    "    Helper function.\n",
    "    Writes a log file with all notes and\n",
    "    error messages from a scraping \"session\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    log_file_name : str\n",
    "        Name of the log file (should be a .txt file).\n",
    "    text : str\n",
    "        Text to write to the log file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(log_file_name, \"a\") as log_file:\n",
    "        log_file.write(text)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape10K(browse_url_base, filing_url_base, doc_url_base, cik, log_file_name):\n",
    "    \n",
    "    '''\n",
    "    Scrapes all 10-Ks and 10-K405s for a particular \n",
    "    CIK from EDGAR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    browse_url_base : str\n",
    "        Base URL for browsing EDGAR.\n",
    "    filing_url_base : str\n",
    "        Base URL for filings listings on EDGAR.\n",
    "    doc_url_base : str\n",
    "        Base URL for one filing's document tables\n",
    "        page on EDGAR.\n",
    "    cik : str\n",
    "        Central Index Key.\n",
    "    log_file_name : str\n",
    "        Name of the log file (should be a .txt file).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Check if we've already scraped this CIK\n",
    "    try:\n",
    "        os.mkdir(cik)\n",
    "    except OSError:\n",
    "        print(\"Already scraped CIK\", cik)\n",
    "        return\n",
    "    \n",
    "    # If we haven't, go into the directory for that CIK\n",
    "    os.chdir(cik)\n",
    "    \n",
    "    print('Scraping CIK', cik)\n",
    "    \n",
    "    # Request list of 10-K filings\n",
    "    res = requests.get(browse_url_base % cik)\n",
    "    \n",
    "    # If the request failed, log the failure and exit\n",
    "    if res.status_code != 200:\n",
    "        os.chdir('..')\n",
    "        os.rmdir(cik) # remove empty dir\n",
    "        text = \"Request failed with error code \" + str(res.status_code) + \\\n",
    "               \"\\nFailed URL: \" + (browse_url_base % cik) + '\\n'\n",
    "        WriteLogFile(log_file_name, text)\n",
    "        return\n",
    "\n",
    "    # If the request doesn't fail, continue...\n",
    "    \n",
    "    # Parse the response HTML using BeautifulSoup\n",
    "    soup = bs.BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "    # Extract all tables from the response\n",
    "    html_tables = soup.find_all('table')\n",
    "    \n",
    "    # Check that the table we're looking for exists\n",
    "    # If it doesn't, exit\n",
    "    if len(html_tables)<3:\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Parse the Filings table\n",
    "    filings_table = pd.read_html(str(html_tables[2]), header=0)[0]\n",
    "    filings_table['Filings'] = [str(x) for x in filings_table['Filings']]\n",
    "\n",
    "    # Get 10-K, 10-K/A, 10-K405 and 10-KT document filings\n",
    "    filings_table = filings_table[(filings_table['Filings'] == '10-K')|(filings_table['Filings'] == '10-K405')|\\\n",
    "                                 (filings_table['Filings'] == '10-K/A')|(filings_table['Filings'] == '10-KT')]\n",
    "\n",
    "    # If filings table doesn't have any\n",
    "    # 10-Ks or 10-K405s, exit\n",
    "    if len(filings_table)==0:\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Get accession number for each 10-K and 10-K405 filing\n",
    "    filings_table['Acc_No'] = [x.replace('\\xa0',' ')\n",
    "                               .split('Acc-no: ')[1]\n",
    "                               .split(' ')[0] for x in filings_table['Description']]\n",
    "\n",
    "    # Iterate through each filing and \n",
    "    # scrape the corresponding document...\n",
    "    for index, row in filings_table.iterrows():\n",
    "        \n",
    "        # Get the accession number for the filing\n",
    "        acc_no = str(row['Acc_No'])\n",
    "        \n",
    "        # Navigate to the page for the filing\n",
    "        docs_page = requests.get(filing_url_base % (cik, acc_no))\n",
    "        \n",
    "        # If request fails, log the failure\n",
    "        # and skip to the next filing\n",
    "        if docs_page.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(docs_page.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (filing_url_base % (cik, acc_no)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "\n",
    "        # If request succeeds, keep going...\n",
    "        \n",
    "        # Parse the table of documents for the filing\n",
    "        docs_page_soup = bs.BeautifulSoup(docs_page.text, 'lxml')\n",
    "        docs_html_tables = docs_page_soup.find_all('table')\n",
    "        if len(docs_html_tables)==0:\n",
    "            continue\n",
    "        docs_table = pd.read_html(str(docs_html_tables[0]), header=0)[0]\n",
    "        docs_table['Type'] = [str(x) for x in docs_table['Type']]\n",
    "        \n",
    "        # Get the 10-K,10-K405, 10-KT and 10-K/A entries for the filing\n",
    "        docs_table = docs_table[(docs_table['Type'] == '10-K')|(docs_table['Type'] == '10-K405')|\\\n",
    "                                (docs_table['Type'] == '10-K/A')|(docs_table['Type'] == '10-KT')]\n",
    "        \n",
    "        # If there aren't any 10-K or 10-K405 entries,\n",
    "        # skip to the next filing\n",
    "        if len(docs_table)==0:\n",
    "            continue\n",
    "        # If there are 10-K or 10-K405 or 10-K/A entries,\n",
    "        # grab the first document\n",
    "        elif len(docs_table)>0:\n",
    "            docs_table = docs_table.iloc[0]\n",
    "        \n",
    "        docname = str(docs_table['Document']).split(' ')[0]   # required for recent submissions\n",
    "        \n",
    "        # If that first entry is unavailable,\n",
    "        # log the failure and exit\n",
    "        if str(docname) == 'nan':\n",
    "            os.chdir('..')\n",
    "            text = 'File with CIK: %s and Acc_No: %s is unavailable' % (cik, acc_no) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue       \n",
    "        \n",
    "        # If it is available, continue...\n",
    "        \n",
    "        # Request the file\n",
    "        file = requests.get(doc_url_base % (cik, acc_no.replace('-', ''), docname))\n",
    "        \n",
    "        # If the request fails, log the failure and exit\n",
    "        if file.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(file.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (doc_url_base % (cik, acc_no.replace('-', ''), docname)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "        \n",
    "        # If it succeeds, keep going...\n",
    "        \n",
    "        # Save the file in appropriate format: if it is a modified report, _a is noted; otherwise _r is noted\n",
    "        if docs_table['Type']=='10-K/A':\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'a'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date  + '_'+'a'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        elif docs_table['Type']=='10-KT':\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'t'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date  + '_'+'t'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        else:\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'r'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'r'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        \n",
    "    # Move back to the main 10-K directory\n",
    "    os.chdir('..')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scrape10Q(browse_url_base, filing_url_base, doc_url_base, cik, log_file_name):\n",
    "    \n",
    "    '''\n",
    "    Scrapes all 10-Qs for a particular CIK from EDGAR.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    browse_url_base : str\n",
    "        Base URL for browsing EDGAR.\n",
    "    filing_url_base : str\n",
    "        Base URL for filings listings on EDGAR.\n",
    "    doc_url_base : str\n",
    "        Base URL for one filing's document tables\n",
    "        page on EDGAR.\n",
    "    cik : str\n",
    "        Central Index Key.\n",
    "    log_file_name : str\n",
    "        Name of the log file (should be a .txt file).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Check if we've already scraped this CIK\n",
    "    try:\n",
    "        os.mkdir(cik)\n",
    "    except OSError:\n",
    "        print(\"Already scraped CIK\", cik)\n",
    "        return\n",
    "    \n",
    "    # If we haven't, go into the directory for that CIK\n",
    "    os.chdir(cik)\n",
    "    \n",
    "    print('Scraping CIK', cik)\n",
    "    \n",
    "    # Request list of 10-Q filings\n",
    "    res = requests.get(browse_url_base % cik)\n",
    "    \n",
    "    # If the request failed, log the failure and exit\n",
    "    if res.status_code != 200:\n",
    "        os.chdir('..')\n",
    "        os.rmdir(cik) # remove empty dir\n",
    "        text = \"Request failed with error code \" + str(res.status_code) + \\\n",
    "               \"\\nFailed URL: \" + (browse_url_base % cik) + '\\n'\n",
    "        WriteLogFile(log_file_name, text)\n",
    "        return\n",
    "    \n",
    "    # If the request doesn't fail, continue...\n",
    "\n",
    "    # Parse the response HTML using BeautifulSoup\n",
    "    soup = bs.BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "    # Extract all tables from the response\n",
    "    html_tables = soup.find_all('table')\n",
    "    \n",
    "    # Check that the table we're looking for exists\n",
    "    # If it doesn't, exit\n",
    "    if len(html_tables)<3:\n",
    "        print(\"table too short\")\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Parse the Filings table\n",
    "    filings_table = pd.read_html(str(html_tables[2]), header=0)[0]\n",
    "    filings_table['Filings'] = [str(x) for x in filings_table['Filings']]\n",
    "\n",
    "    # Get 10-Q， 10-QT and 10-Q/A document filings\n",
    "    filings_table = filings_table[(filings_table['Filings'] == '10-Q')|(filings_table['Filings'] == '10-Q/A')\\\n",
    "                                 |(filings_table['Filings'] == '10-QT')]\n",
    "\n",
    "    # If filings table doesn't have any\n",
    "    # 10-Ks or 10-K405s, exit\n",
    "    if len(filings_table)==0:\n",
    "        os.chdir('..')\n",
    "        return\n",
    "    \n",
    "    # Get accession number for each 10-K and 10-K405 filing\n",
    "    filings_table['Acc_No'] = [x.replace('\\xa0',' ')\n",
    "                               .split('Acc-no: ')[1]\n",
    "                               .split(' ')[0] for x in filings_table['Description']]\n",
    "\n",
    "    # Iterate through each filing and \n",
    "    # scrape the corresponding document...\n",
    "    for index, row in filings_table.iterrows():\n",
    "        \n",
    "        # Get the accession number for the filing\n",
    "        acc_no = str(row['Acc_No'])\n",
    "        \n",
    "        # Navigate to the page for the filing\n",
    "        docs_page = requests.get(filing_url_base % (cik, acc_no))\n",
    "        \n",
    "        # If request fails, log the failure\n",
    "        # and skip to the next filing    \n",
    "        if docs_page.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(docs_page.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (filing_url_base % (cik, acc_no)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "            \n",
    "        # If request succeeds, keep going...\n",
    "        \n",
    "        # Parse the table of documents for the filing\n",
    "        docs_page_soup = bs.BeautifulSoup(docs_page.text, 'lxml')\n",
    "        docs_html_tables = docs_page_soup.find_all('table')\n",
    "        if len(docs_html_tables)==0:\n",
    "            continue\n",
    "        docs_table = pd.read_html(str(docs_html_tables[0]), header=0)[0]\n",
    "        docs_table['Type'] = [str(x) for x in docs_table['Type']]\n",
    "        \n",
    "        # Get the 10-Q entries for the filing\n",
    "        docs_table = docs_table[(docs_table['Type'] == '10-Q')|(docs_table['Type'] == '10-Q/A')|\\\n",
    "                               (docs_table['Type'] == '10-QT')]\n",
    "        \n",
    "        # If there aren't any 10-K or 10-K405 entries,\n",
    "        # skip to the next filing\n",
    "        if len(docs_table)==0:\n",
    "            continue\n",
    "        # If there are 10-K or 10-K405 entries,\n",
    "        # grab the first document\n",
    "        elif len(docs_table)>0:\n",
    "            docs_table = docs_table.iloc[0]\n",
    "        \n",
    "        docname = str(docs_table['Document']).split(' ')[0]   # required for recent submissions\n",
    "        \n",
    "        # If that first entry is unavailable,\n",
    "        # log the failure and exit\n",
    "        if str(docname) == 'nan':\n",
    "            os.chdir('..')\n",
    "            text = 'File with CIK: %s and Acc_No: %s is unavailable' % (cik, acc_no) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue       \n",
    "        \n",
    "        # If it is available, continue...\n",
    "        \n",
    "        # Request the file\n",
    "        file = requests.get(doc_url_base % (cik, acc_no.replace('-', ''), docname))\n",
    "        \n",
    "        # If the request fails, log the failure and exit\n",
    "        if file.status_code != 200:\n",
    "            os.chdir('..')\n",
    "            text = \"Request failed with error code \" + str(file.status_code) + \\\n",
    "                   \"\\nFailed URL: \" + (doc_url_base % (cik, acc_no.replace('-', ''), docname)) + '\\n'\n",
    "            WriteLogFile(log_file_name, text)\n",
    "            os.chdir(cik)\n",
    "            continue\n",
    "            \n",
    "        # If it succeeds, keep going...\n",
    "        \n",
    "        # Save the file in appropriate format\n",
    "        if docs_table['Type']=='10-Q/A':\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'a'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date  + '_'+'a'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        elif docs_table['Type']=='10-QT':\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'t'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date  + '_'+'t'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        else:\n",
    "            if '.txt' in docname:\n",
    "        # Save text as TXT\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'r'+'.txt'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "            else:\n",
    "        # Save text as HTML\n",
    "                date = str(row['Filing Date'])\n",
    "                filename = cik + '_' + date + '_'+'r'+'.html'\n",
    "                html_file = open(filename, 'a')\n",
    "                html_file.write(file.text)\n",
    "                html_file.close()\n",
    "        \n",
    "    # Move back to the main 10-Q directory\n",
    "    os.chdir('..')\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 312/505 [00:00<00:00, 1235.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already scraped CIK 0000066740\n",
      "Already scraped CIK 0000001800\n",
      "Already scraped CIK 0001551152\n",
      "Already scraped CIK 0000815094\n",
      "Already scraped CIK 0001467373\n",
      "Already scraped CIK 0000718877\n",
      "Already scraped CIK 0000796343\n",
      "Already scraped CIK 0000002488\n",
      "Already scraped CIK 0001158449\n",
      "Already scraped CIK 0000874761\n",
      "Already scraped CIK 0000004977\n",
      "Already scraped CIK 0001090872\n",
      "Already scraped CIK 0000002969\n",
      "Already scraped CIK 0001086222\n",
      "Already scraped CIK 0000766421\n",
      "Already scraped CIK 0000915913\n",
      "Already scraped CIK 0001035443\n",
      "Already scraped CIK 0000899866\n",
      "Already scraped CIK 0001097149\n",
      "Already scraped CIK 0001579241\n",
      "Already scraped CIK 0001101215\n",
      "Already scraped CIK 0000352541\n",
      "Already scraped CIK 0000899051\n",
      "Already scraped CIK 0001652044\n",
      "Already scraped CIK 0001652044\n",
      "Already scraped CIK 0000764180\n",
      "Already scraped CIK 0001018724\n",
      "Already scraped CIK 0001748790\n",
      "Already scraped CIK 0001002910\n",
      "Already scraped CIK 0000006201\n",
      "Already scraped CIK 0000004904\n",
      "Already scraped CIK 0000004962\n",
      "Already scraped CIK 0000005272\n",
      "Already scraped CIK 0001053507\n",
      "Already scraped CIK 0001410636\n",
      "Already scraped CIK 0000820027\n",
      "Already scraped CIK 0001140859\n",
      "Already scraped CIK 0001037868\n",
      "Already scraped CIK 0000318154\n",
      "Already scraped CIK 0000820313\n",
      "Already scraped CIK 0000006281\n",
      "Already scraped CIK 0001013462\n",
      "Already scraped CIK 0001156039\n",
      "Already scraped CIK 0000315293\n",
      "Already scraped CIK 0000091142\n",
      "Already scraped CIK 0000006769\n",
      "Already scraped CIK 0000922864\n",
      "Already scraped CIK 0000320193\n",
      "Already scraped CIK 0000006951\n",
      "Already scraped CIK 0001521332\n",
      "Already scraped CIK 0000007084\n",
      "Already scraped CIK 0001596532\n",
      "Already scraped CIK 0000354190\n",
      "Already scraped CIK 0001267238\n",
      "Already scraped CIK 0000732717\n",
      "Already scraped CIK 0000731802\n",
      "Already scraped CIK 0000769397\n",
      "Already scraped CIK 0000008670\n",
      "Already scraped CIK 0000866787\n",
      "Already scraped CIK 0000915912\n",
      "Already scraped CIK 0000008818\n",
      "Already scraped CIK 0001701605\n",
      "Already scraped CIK 0000009389\n",
      "Already scraped CIK 0000070858\n",
      "Already scraped CIK 0001390777\n",
      "Already scraped CIK 0000010456\n",
      "Already scraped CIK 0000010795\n",
      "Already scraped CIK 0001067983\n",
      "Already scraped CIK 0000764478\n",
      "Already scraped CIK 0000875045\n",
      "Already scraped CIK 0001364742\n",
      "Already scraped CIK 0000012927\n",
      "Already scraped CIK 0001075531\n",
      "Already scraped CIK 0000908255\n",
      "Already scraped CIK 0001037540\n",
      "Already scraped CIK 0000885725\n",
      "Already scraped CIK 0000014272\n",
      "Already scraped CIK 0001730168\n",
      "Already scraped CIK 0001383312\n",
      "Already scraped CIK 0000014693\n",
      "Already scraped CIK 0001043277\n",
      "Already scraped CIK 0000858470\n",
      "Already scraped CIK 0000813672\n",
      "Already scraped CIK 0000016732\n",
      "Already scraped CIK 0000927628\n",
      "Already scraped CIK 0000721371\n",
      "Already scraped CIK 0001170010\n",
      "Already scraped CIK 0000815097\n",
      "Already scraped CIK 0001783180\n",
      "Already scraped CIK 0000018230\n",
      "Already scraped CIK 0001374310\n",
      "Already scraped CIK 0001138118\n",
      "Already scraped CIK 0001402057\n",
      "Already scraped CIK 0001306830\n",
      "Already scraped CIK 0001071739\n",
      "Already scraped CIK 0001130310\n",
      "Already scraped CIK 0000018926\n",
      "Already scraped CIK 0000804753\n",
      "Already scraped CIK 0001324404\n",
      "Already scraped CIK 0000316709\n",
      "Already scraped CIK 0001091667\n",
      "Already scraped CIK 0000093410\n",
      "Already scraped CIK 0001058090\n",
      "Already scraped CIK 0000896159\n",
      "Already scraped CIK 0000313927\n",
      "Already scraped CIK 0000701221\n",
      "Already scraped CIK 0000020286\n",
      "Already scraped CIK 0000723254\n",
      "Already scraped CIK 0000858877\n",
      "Already scraped CIK 0000831001\n",
      "Already scraped CIK 0000759944\n",
      "Already scraped CIK 0000877890\n",
      "Already scraped CIK 0000021076\n",
      "Already scraped CIK 0001156375\n",
      "Already scraped CIK 0000811156\n",
      "Already scraped CIK 0000021344\n",
      "Already scraped CIK 0001058290\n",
      "Already scraped CIK 0000021665\n",
      "Already scraped CIK 0001166691\n",
      "Already scraped CIK 0000028412\n",
      "Already scraped CIK 0000023217\n",
      "Already scraped CIK 0001358071\n",
      "Already scraped CIK 0001163165\n",
      "Already scraped CIK 0001047862\n",
      "Already scraped CIK 0000016918\n",
      "Already scraped CIK 0000711404\n",
      "Already scraped CIK 0000900075\n",
      "Already scraped CIK 0000024741\n",
      "Already scraped CIK 0001755672\n",
      "Already scraped CIK 0000909832\n",
      "Already scraped CIK 0001024305\n",
      "Already scraped CIK 0001051470\n",
      "Already scraped CIK 0000277948\n",
      "Already scraped CIK 0000026172\n",
      "Already scraped CIK 0000064803\n",
      "Already scraped CIK 0000882184\n",
      "Already scraped CIK 0000313616\n",
      "Already scraped CIK 0000940944\n",
      "Already scraped CIK 0000927066\n",
      "Already scraped CIK 0000315189\n",
      "Already scraped CIK 0000027904\n",
      "Already scraped CIK 0000818479\n",
      "Already scraped CIK 0001090012\n",
      "Already scraped CIK 0001093557\n",
      "Already scraped CIK 0001539838\n",
      "Already scraped CIK 0001297996\n",
      "Already scraped CIK 0001393612\n",
      "Already scraped CIK 0001437107\n",
      "Already scraped CIK 0001437107\n",
      "Already scraped CIK 0001001082\n",
      "Already scraped CIK 0000029534\n",
      "Already scraped CIK 0000935703\n",
      "Already scraped CIK 0000715957\n",
      "Already scraped CIK 0001286681\n",
      "Already scraped CIK 0000029905\n",
      "Already scraped CIK 0001751788\n",
      "Already scraped CIK 0000936340\n",
      "Already scraped CIK 0001326160\n",
      "Already scraped CIK 0000783280\n",
      "Already scraped CIK 0001666700\n",
      "Already scraped CIK 0001688568\n",
      "Already scraped CIK 0001015780\n",
      "Already scraped CIK 0000915389\n",
      "Already scraped CIK 0001551182\n",
      "Already scraped CIK 0001065088\n",
      "Already scraped CIK 0000031462\n",
      "Already scraped CIK 0000827052\n",
      "Already scraped CIK 0001099800\n",
      "Already scraped CIK 0000712515\n",
      "Already scraped CIK 0000032604\n",
      "Already scraped CIK 0000065984\n",
      "Already scraped CIK 0000821189\n",
      "Already scraped CIK 0000033185\n",
      "Already scraped CIK 0001101239\n",
      "Already scraped CIK 0000906107\n",
      "Already scraped CIK 0000920522\n",
      "Already scraped CIK 0001001250\n",
      "Already scraped CIK 0001711269\n",
      "Already scraped CIK 0000072741\n",
      "Already scraped CIK 0001095073\n",
      "Already scraped CIK 0001109357\n",
      "Already scraped CIK 0001324424\n",
      "Already scraped CIK 0000746515\n",
      "Already scraped CIK 0001289490\n",
      "Already scraped CIK 0000034088\n",
      "Already scraped CIK 0001048695\n",
      "Already scraped CIK 0001326801\n",
      "Already scraped CIK 0000815556\n",
      "Already scraped CIK 0000034903\n",
      "Already scraped CIK 0001048911\n",
      "Already scraped CIK 0001136893\n",
      "Already scraped CIK 0000035527\n",
      "Already scraped CIK 0001031296\n",
      "Already scraped CIK 0001132979\n",
      "Already scraped CIK 0000798354\n",
      "Already scraped CIK 0001175454\n",
      "Already scraped CIK 0000354908\n",
      "Already scraped CIK 0000030625\n",
      "Already scraped CIK 0000037785\n",
      "Already scraped CIK 0000037996\n",
      "Already scraped CIK 0001262039\n",
      "Already scraped CIK 0001659166\n",
      "Already scraped CIK 0001519751\n",
      "Already scraped CIK 0001308161\n",
      "Already scraped CIK 0001308161\n",
      "Already scraped CIK 0000038777\n",
      "Already scraped CIK 0000831259\n",
      "Already scraped CIK 0000039911\n",
      "Already scraped CIK 0001121788\n",
      "Already scraped CIK 0000749251\n",
      "Already scraped CIK 0000040533\n",
      "Already scraped CIK 0000040545\n",
      "Already scraped CIK 0000040704\n",
      "Already scraped CIK 0001467858\n",
      "Already scraped CIK 0000040987\n",
      "Already scraped CIK 0000882095\n",
      "Already scraped CIK 0000320335\n",
      "Already scraped CIK 0001123360\n",
      "Already scraped CIK 0000886982\n",
      "Already scraped CIK 0000277135\n",
      "Already scraped CIK 0000012659\n",
      "Already scraped CIK 0000045012\n",
      "Already scraped CIK 0001359841\n",
      "Already scraped CIK 0000793952\n",
      "Already scraped CIK 0000874766\n",
      "Already scraped CIK 0000046080\n",
      "Already scraped CIK 0000860730\n",
      "Already scraped CIK 0000765880\n",
      "Already scraped CIK 0001000228\n",
      "Already scraped CIK 0000047111\n",
      "Already scraped CIK 0000004447\n",
      "Already scraped CIK 0001645590\n",
      "Already scraped CIK 0001585689\n",
      "Already scraped CIK 0000048039\n",
      "Already scraped CIK 0000859737\n",
      "Already scraped CIK 0000354950\n",
      "Already scraped CIK 0000773840\n",
      "Already scraped CIK 0000048465\n",
      "Already scraped CIK 0001070750\n",
      "Already scraped CIK 0000004281\n",
      "Already scraped CIK 0000047217\n",
      "Already scraped CIK 0000049071\n",
      "Already scraped CIK 0000049196\n",
      "Already scraped CIK 0001501585\n",
      "Already scraped CIK 0000832101\n",
      "Already scraped CIK 0000874716\n",
      "Already scraped CIK 0001598014\n",
      "Already scraped CIK 0000049826\n",
      "Already scraped CIK 0001110803\n",
      "Already scraped CIK 0000879169\n",
      "Already scraped CIK 0001699150\n",
      "Already scraped CIK 0000050863\n",
      "Already scraped CIK 0001571949\n",
      "Already scraped CIK 0000051143\n",
      "Already scraped CIK 0000051434\n",
      "Already scraped CIK 0000051644\n",
      "Already scraped CIK 0000051253\n",
      "Already scraped CIK 0000896878\n",
      "Already scraped CIK 0001035267\n",
      "Already scraped CIK 0000914208\n",
      "Already scraped CIK 0001111928\n",
      "Already scraped CIK 0001478242\n",
      "Already scraped CIK 0001020569\n",
      "Already scraped CIK 0000779152\n",
      "Already scraped CIK 0000052988\n",
      "Already scraped CIK 0000728535\n",
      "Already scraped CIK 0000091419\n",
      "Already scraped CIK 0000200406\n",
      "Already scraped CIK 0000833444\n",
      "Already scraped CIK 0000019617\n",
      "Already scraped CIK 0001043604\n",
      "Already scraped CIK 0000054480\n",
      "Already scraped CIK 0000055067\n",
      "Already scraped CIK 0000091576\n",
      "Already scraped CIK 0001601046\n",
      "Already scraped CIK 0000055785\n",
      "Already scraped CIK 0000879101\n",
      "Already scraped CIK 0001506307\n",
      "Already scraped CIK 0000319201\n",
      "Already scraped CIK 0000885639\n",
      "Already scraped CIK 0001637459\n",
      "Already scraped CIK 0000056873\n",
      "Already scraped CIK 0000701985\n",
      "Already scraped CIK 0000202058\n",
      "Already scraped CIK 0000920148\n",
      "Already scraped CIK 0000707549\n",
      "Already scraped CIK 0001679273\n",
      "Already scraped CIK 0001300514\n",
      "Already scraped CIK 0000058492\n",
      "Already scraped CIK 0001336920\n",
      "Already scraped CIK 0000920760\n",
      "Already scraped CIK 0000059478\n",
      "Already scraped CIK 0000059558\n",
      "Already scraped CIK 0001707925\n",
      "Already scraped CIK 0001335258\n",
      "Already scraped CIK 0001065696\n",
      "Already scraped CIK 0000936468\n",
      "Already scraped CIK 0000060086\n",
      "Already scraped CIK 0000060667\n",
      "Already scraped CIK 0001489393\n",
      "Already scraped CIK 0000036270\n",
      "Already scraped CIK 0000101778\n",
      "Already scraped CIK 0001510295\n",
      "Already scraped CIK 0001278021\n",
      "Already scraped CIK 0001048286\n",
      "Already scraped CIK 0000062709\n",
      "Already scraped CIK 0000916076\n",
      "Already scraped CIK 0000062996\n",
      "Already scraped CIK 0001141391\n",
      "Already scraped CIK 0000063754\n",
      "Already scraped CIK 0000743316\n",
      "Already scraped CIK 0000063908\n",
      "Already scraped CIK 0000927653\n",
      "Already scraped CIK 0001613103\n",
      "Already scraped CIK 0000310158\n",
      "Already scraped CIK 0001099219\n",
      "Already scraped CIK 0001037646\n",
      "Already scraped CIK 0000789570\n",
      "Already scraped CIK 0000827054\n",
      "Already scraped CIK 0000723125\n",
      "Already scraped CIK 0000789019\n",
      "Already scraped CIK 0000912595\n",
      "Already scraped CIK 0000851968\n",
      "Already scraped CIK 0000024545\n",
      "Already scraped CIK 0001103982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already scraped CIK 0000865752\n",
      "Already scraped CIK 0001059556\n",
      "Already scraped CIK 0000895421\n",
      "Already scraped CIK 0001285785\n",
      "Already scraped CIK 0000068505\n",
      "Already scraped CIK 0001408198\n",
      "Already scraped CIK 0001623613\n",
      "Already scraped CIK 0001120193\n",
      "Already scraped CIK 0001021860\n",
      "Already scraped CIK 0001002047\n",
      "Already scraped CIK 0001065280\n",
      "Already scraped CIK 0000814453\n",
      "Already scraped CIK 0001164727\n",
      "Already scraped CIK 0001564708\n",
      "Already scraped CIK 0001564708\n",
      "Already scraped CIK 0000753308\n",
      "Already scraped CIK 0001492633\n",
      "Already scraped CIK 0000320187\n",
      "Already scraped CIK 0001111711\n",
      "Already scraped CIK 0000072207\n",
      "Already scraped CIK 0000072333\n",
      "Already scraped CIK 0000702165\n",
      "Already scraped CIK 0000073124\n",
      "Already scraped CIK 0001133421\n",
      "Already scraped CIK 0000849399\n",
      "Already scraped CIK 0001513761\n",
      "Already scraped CIK 0001013871\n",
      "Already scraped CIK 0000073309\n",
      "Already scraped CIK 0001045810\n",
      "Already scraped CIK 0000906163\n",
      "Already scraped CIK 0000898173\n",
      "Already scraped CIK 0000797468\n",
      "Already scraped CIK 0000878927\n",
      "Already scraped CIK 0000029989\n",
      "Already scraped CIK 0001039684\n",
      "Already scraped CIK 0001341439\n",
      "Already scraped CIK 0001781335\n",
      "Already scraped CIK 0000075362\n",
      "Already scraped CIK 0000075677\n",
      "Already scraped CIK 0000076334\n",
      "Already scraped CIK 0000723531\n",
      "Already scraped CIK 0001590955\n",
      "Already scraped CIK 0001633917\n",
      "Already scraped CIK 0000077360\n",
      "Already scraped CIK 0001378946\n",
      "Already scraped CIK 0000077476\n",
      "Already scraped CIK 0000031791\n",
      "Already scraped CIK 0001585364\n",
      "Already scraped CIK 0000078003\n",
      "Already scraped CIK 0001413329\n",
      "Already scraped CIK 0001534701\n",
      "Already scraped CIK 0000764622\n",
      "Already scraped CIK 0001038357\n",
      "Already scraped CIK 0000713676\n",
      "Already scraped CIK 0000079879\n",
      "Already scraped CIK 0000922224\n",
      "Already scraped CIK 0001126328\n",
      "Already scraped CIK 0000080424\n",
      "Already scraped CIK 0000080661\n",
      "Already scraped CIK 0001045609\n",
      "Already scraped CIK 0001137774\n",
      "Already scraped CIK 0000788784\n",
      "Already scraped CIK 0001393311\n",
      "Already scraped CIK 0000822416\n",
      "Already scraped CIK 0000078239\n",
      "Already scraped CIK 0001604778\n",
      "Already scraped CIK 0001050915\n",
      "Already scraped CIK 0000804328\n",
      "Already scraped CIK 0001022079\n",
      "Already scraped CIK 0001037038\n",
      "Already scraped CIK 0000720005\n",
      "Already scraped CIK 0000101829\n",
      "Already scraped CIK 0000726728\n",
      "Already scraped CIK 0000910606\n",
      "Already scraped CIK 0000872589\n",
      "Already scraped CIK 0001281761\n",
      "Already scraped CIK 0001060391\n",
      "Already scraped CIK 0000943819\n",
      "Already scraped CIK 0000315213\n",
      "Already scraped CIK 0001024478\n",
      "Already scraped CIK 0000084839\n",
      "Already scraped CIK 0000882835\n",
      "Already scraped CIK 0000745732\n",
      "Already scraped CIK 0000884887\n",
      "Already scraped CIK 0000064040\n",
      "Already scraped CIK 0001108524\n",
      "Already scraped CIK 0001034054\n",
      "Already scraped CIK 0000087347\n",
      "Already scraped CIK 0001137789\n",
      "Already scraped CIK 0001012100\n",
      "Already scraped CIK 0001032208\n",
      "Already scraped CIK 0001373715\n",
      "Already scraped CIK 0000089800\n",
      "Already scraped CIK 0001063761\n",
      "Already scraped CIK 0000004127\n",
      "Already scraped CIK 0001040971\n",
      "Already scraped CIK 0000091440\n",
      "Already scraped CIK 0000092122\n",
      "Already scraped CIK 0000092380\n",
      "Already scraped CIK 0000093556\n",
      "Already scraped CIK 0000829224\n",
      "Already scraped CIK 0000093751\n",
      "Already scraped CIK 0001757898\n",
      "Already scraped CIK 0000310764\n",
      "Already scraped CIK 0000719739\n",
      "Already scraped CIK 0001601712\n",
      "Already scraped CIK 0000883241\n",
      "Already scraped CIK 0000096021\n",
      "Already scraped CIK 0001283699\n",
      "Already scraped CIK 0001113169\n",
      "Already scraped CIK 0000946581\n",
      "Already scraped CIK 0001116132\n",
      "Already scraped CIK 0000027419\n",
      "Already scraped CIK 0001385157\n",
      "Scraping CIK 0001681459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 440/505 [00:05<00:00, 80.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000096943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 441/505 [00:27<07:09,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000097476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 442/505 [00:49<11:47, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000217346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 443/505 [01:14<15:58, 15.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000097745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 444/505 [01:41<19:16, 18.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000098246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 445/505 [02:03<19:41, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000109198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 446/505 [02:21<19:04, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000916365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 447/505 [02:41<18:45, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001466258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▊ | 448/505 [02:52<16:03, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001260221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 449/505 [03:07<15:15, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000086312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 450/505 [03:32<17:17, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000092230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 451/505 [03:54<18:00, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001418091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 452/505 [04:02<14:19, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000100493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 453/505 [04:26<16:04, 18.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000074208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 454/505 [04:51<17:31, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001403568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 455/505 [05:23<19:57, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000036104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 456/505 [05:43<18:37, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001336917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 457/505 [06:00<16:53, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already scraped CIK 0001336917\n",
      "Scraping CIK 0000100885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 459/505 [06:26<14:16, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000100517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 460/505 [06:49<15:01, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000731766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 461/505 [07:11<15:02, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001090727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 462/505 [07:30<14:27, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001067701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 463/505 [07:55<15:03, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000352915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 464/505 [08:19<15:16, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000005513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 465/505 [08:42<15:04, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000103379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 466/505 [09:07<15:01, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001035002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 467/505 [09:28<14:19, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000203527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 468/505 [09:55<14:39, 23.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000740260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 469/505 [10:24<15:13, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001014473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 470/505 [10:45<14:07, 24.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001442145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 471/505 [10:56<11:29, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000732712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 472/505 [11:19<11:36, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000875320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▎| 473/505 [11:40<11:15, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001339947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 474/505 [11:56<09:58, 19.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001403161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 475/505 [12:10<08:59, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000899689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 476/505 [12:47<11:26, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001396009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 477/505 [13:00<09:31, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000011544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 478/505 [13:20<09:04, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000943452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 479/505 [13:43<09:11, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000104169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 480/505 [14:04<08:48, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001618921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 481/505 [14:10<06:35, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001001039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 482/505 [14:33<07:03, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000823768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 483/505 [14:56<07:15, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001000697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 484/505 [15:17<07:04, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000783325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 485/505 [15:42<07:12, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000072971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 486/505 [16:04<06:55, 21.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000766704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 487/505 [16:33<07:09, 23.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000105770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 488/505 [16:54<06:33, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000106040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 489/505 [17:16<06:01, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001365135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 490/505 [17:30<05:01, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001636023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 491/505 [17:34<03:32, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000106535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 492/505 [17:56<03:43, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000106640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 493/505 [18:17<03:40, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000107263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 494/505 [18:41<03:43, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001140536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 495/505 [19:05<03:33, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001174922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 496/505 [19:36<03:38, 24.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000072903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 497/505 [20:04<03:22, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000108772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 498/505 [20:31<03:00, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000743988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 499/505 [20:51<02:24, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001524472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 500/505 [21:00<01:37, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001041061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 501/505 [21:21<01:20, 20.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0000877212\n"
     ]
    }
   ],
   "source": [
    "# Run the function to scrape 10-Ks\n",
    "\n",
    "# Define parameters\n",
    "browse_url_base_10k = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=%s&type=10-K'\n",
    "filing_url_base_10k = 'http://www.sec.gov/Archives/edgar/data/%s/%s-index.html'\n",
    "doc_url_base_10k = 'http://www.sec.gov/Archives/edgar/data/%s/%s/%s'\n",
    "\n",
    "# Set correct directory\n",
    "os.chdir(pathname_10k)\n",
    "\n",
    "# Initialize log file\n",
    "# (log file name = the time we initiate scraping session)\n",
    "time = strftime(\"%Y-%m-%d %Hh%Mm%Ss\", gmtime())\n",
    "log_file_name = 'log '+time+'.txt'\n",
    "with open(log_file_name, 'a') as log_file:\n",
    "    log_file.close()\n",
    "\n",
    "# Iterate over CIKs and scrape 10-Ks\n",
    "for cik in tqdm(sptable['CIK']):\n",
    "    Scrape10K(browse_url_base=browse_url_base_10k, \n",
    "          filing_url_base=filing_url_base_10k, \n",
    "          doc_url_base=doc_url_base_10k, \n",
    "          cik=cik,\n",
    "          log_file_name=log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to scrape 10-Qs\n",
    "\n",
    "# Define parameters\n",
    "browse_url_base_10q = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=%s&type=10-Q&count=1000'\n",
    "filing_url_base_10q = 'http://www.sec.gov/Archives/edgar/data/%s/%s-index.html'\n",
    "doc_url_base_10q = 'http://www.sec.gov/Archives/edgar/data/%s/%s/%s'\n",
    "\n",
    "# Set correct directory (fill this out yourself!)\n",
    "os.chdir(pathname_10q)\n",
    "\n",
    "# Initialize log file\n",
    "# (log file name = the time we initiate scraping session)\n",
    "time = strftime(\"%Y-%m-%d %Hh%Mm%Ss\", gmtime())\n",
    "log_file_name = 'log '+time+'.txt'\n",
    "log_file = open(log_file_name, 'a')\n",
    "log_file.close()\n",
    "\n",
    "# Iterate over CIKs and scrape 10-Ks\n",
    "for cik in tqdm(sptable['CIK']):\n",
    "    Scrape10Q(browse_url_base=browse_url_base_10q, \n",
    "          filing_url_base=filing_url_base_10q, \n",
    "          doc_url_base=doc_url_base_10q, \n",
    "          cik=cik,\n",
    "          log_file_name=log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
